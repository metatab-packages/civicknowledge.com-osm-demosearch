{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import metapack as mp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display \n",
    "from itertools import chain \n",
    "from tqdm import tqdm\n",
    "import libgeohash as gh\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "from shapely.wkt import loads as loads_wkt\n",
    "from geoid.censusnames import stusab\n",
    "import rowgenerators as rg\n",
    "import utm\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from demosearch.util import munge_pbar,  run_mp, gh_data_path, disaggregate\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')\n",
    "mp.jupyter.init()\n",
    "\n",
    "utm_crs = 26911\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Open Street Map Extract for Demographic Search</h1>\n",
       "<p><code>civicknowledge.com-osm-demosearch-1.1.1</code> Last Update: 2021-01-29T00:14:05</p>\n",
       "<p>__</p>\n",
       "<h2>Contacts</h2>\n",
       "<ul>\n",
       "<li><strong>Wrangler</strong> <a href=\"mailto:eric@civicknowledge.com\">Eric Busboom</a>, <a href=\"http://civicknowledge.com\">Civic Knowledge</a></li>\n",
       "</ul>\n",
       "<h2>Resources</h2>\n",
       "<ul>\n",
       "<li><strong> <a href=\"notebooks/ExtractPoints.ipynb#geohash_tags\">geohash_tags</a></strong>. Points converted to counts of tags per geohash</li>\n",
       "</ul>\n",
       "<h2>References</h2>\n",
       "<ul><li> <strong><a href=\"https://download.geofabrik.de/'north-america-latest.osm.pbf\">north-america-latest</a></strong>. OSM North America extract</li><li> <strong>points</string>, <em>data/csv/points.csv</em>. Points from the OSM file</li><li> <strong>lines</string>, <em>data/csv/lines.csv</em>. Lines from the OSM file</li><li> <strong>multipolygons</string>, <em>data/csv/multipolygons.csv</em>. Polygons from the OSM file</li><li> <strong>multilinestrings</string>, <em>data/csv/multilinestrings.csv</em>. Lines from the OSM file</li><li> <strong>other_relations</string>, <em>data/csv/other_relations.csv</em>. Other geo data from the OSM file</li><ul>"
      ],
      "text/plain": [
       "# Open Street Map Extract for Demographic Search\n",
       "`civicknowledge.com-osm-demosearch-1.1.1` Last Update: 2021-01-29T00:14:05\n",
       "\n",
       "__\n",
       "\n",
       "\n",
       "\n",
       "\n",
       " \n",
       "\n",
       "## Contacts\n",
       "\n",
       "* **Wrangler** [Eric Busboom](mailto:eric@civicknowledge.com), [Civic Knowledge](http://civicknowledge.com)\n",
       "\n",
       "## Resources\n",
       "\n",
       "* ** [geohash_tags](notebooks/ExtractPoints.ipynb#geohash_tags)**. Points converted to counts of tags per geohash\n",
       "\n",
       "## References\n",
       "<ul><li> <strong><a href=\"https://download.geofabrik.de/'north-america-latest.osm.pbf\">north-america-latest</a></strong>. OSM North America extract</li><li> <strong>points</string>, <em>data/csv/points.csv</em>. Points from the OSM file</li><li> <strong>lines</string>, <em>data/csv/lines.csv</em>. Lines from the OSM file</li><li> <strong>multipolygons</string>, <em>data/csv/multipolygons.csv</em>. Polygons from the OSM file</li><li> <strong>multilinestrings</string>, <em>data/csv/multilinestrings.csv</em>. Lines from the OSM file</li><li> <strong>other_relations</string>, <em>data/csv/other_relations.csv</em>. Other geo data from the OSM file</li><ul>\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pkg = mp.jupyter.open_package()\n",
    "pkg = mp.jupyter.open_source_package()\n",
    "pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_tags = ['amenity', 'tourism', 'shop', 'leisure', 'natural', 'parking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:60640</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>10</li>\n",
       "  <li><b>Cores: </b>10</li>\n",
       "  <li><b>Memory: </b>400.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:60640' processes=10 threads=10, memory=400.00 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(n_workers=10, threads_per_worker=1, processes=True, memory_limit='40GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.2 ms, sys: 2.78 ms, total: 38 ms\n",
      "Wall time: 36.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fp = pkg.reference('lines').resolved_url.fspath\n",
    "df = dd.read_csv(fp, blocksize='64MB',dtype={'aerialway': 'object', 'barrier': 'object','man_made': 'object'}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "geometry = df.partitions[:1].geometry.apply(shapely.wkt.loads, meta = LineString).compute()\n",
    "#centroids = geometry.centroid\n",
    "#length = geometry.length\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100321"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libgeohash import polygon_to_geohash\n",
    "x = [ polygon_to_geohash(g.envelope, 5) for g in geometry[:500] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9mum',\n",
       " '9mup',\n",
       " '9muw',\n",
       " '9mvx',\n",
       " '9q5b',\n",
       " '9q5c',\n",
       " '9q5d',\n",
       " '9q5f',\n",
       " '9q5s',\n",
       " '9q5v',\n",
       " '9q5y',\n",
       " '9qh0',\n",
       " '9qh2',\n",
       " '9qh4',\n",
       " '9qhy',\n",
       " '9qj0',\n",
       " '9qj3',\n",
       " '9qjp',\n",
       " '9qjr',\n",
       " '9rv0',\n",
       " '9tbq',\n",
       " 'dpbm',\n",
       " 'dpmr',\n",
       " 'dpsb',\n",
       " 'dpt2',\n",
       " 'dpwy',\n",
       " 'dpwz',\n",
       " 'dpxn',\n",
       " 'dpxq',\n",
       " 'dpxt',\n",
       " 'dpxv',\n",
       " 'dpxw',\n",
       " 'dpxy',\n",
       " 'dpz8',\n",
       " 'dpz9',\n",
       " 'dpzc',\n",
       " 'dq8y',\n",
       " 'dqbc',\n",
       " 'dqbf',\n",
       " 'dr46',\n",
       " 'dr8w',\n",
       " 'dr9m',\n",
       " 'dr9n',\n",
       " 'dr9q',\n",
       " 'dr9t',\n",
       " 'dr9v',\n",
       " 'dr9w',\n",
       " 'dr9x',\n",
       " 'dr9y',\n",
       " 'drc7',\n",
       " 'drce',\n",
       " 'drcg',\n",
       " 'drcw',\n",
       " 'drcx',\n",
       " 'drcy',\n",
       " 'drcz',\n",
       " 'drfz',\n",
       " 'dxft',\n",
       " 'dxfv',\n",
       " 'dxfw',\n",
       " 'dxfy',\n",
       " 'f21d',\n",
       " 'f244',\n",
       " 'f24g',\n",
       " 'f255',\n",
       " 'f256',\n",
       " 'f25d',\n",
       " 'f25s',\n",
       " 'f84f',\n",
       " 'f84x',\n",
       " 'f85m',\n",
       " 'f85n',\n",
       " 'f85p',\n",
       " 'f85q',\n",
       " 'f866',\n",
       " 'f868',\n",
       " 'f87b'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([e[:4] for e in chain(*x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    }
   ],
   "source": [
    "t['geometry'] = t.geometry.progress_apply(shapely.wkt.loads)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(t, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(301033.9246679279, 4934358.050100996, 16, 'T'),\n",
       " (294671.8300894175, 4935224.855389891, 16, 'T'),\n",
       " (297281.2512604027, 4928388.635446693, 16, 'T'),\n",
       " (295780.863919666, 4932773.75872271, 16, 'T'),\n",
       " (610215.1387833524, 3733598.8985452726, 11, 'S')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def utm_zone(p)\n",
    "[ utm.from_latlon(*e) for e in  zip(gdf.centroid.y, gdf.centroid.x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POINT (-89.50443509999999 44.5350939)'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.iloc[0].geometry.representative_point().wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-89.50427738814578, 44.53509516507668),\n",
       " (-89.5846188108215, 44.54110758253171),\n",
       " (-89.54912157860954, 44.48036255523982),\n",
       " (-89.56970248573194, 44.519378359705115),\n",
       " (-115.81021301852383, 33.736707921492986)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ e for e in  zip(gdf.centroid.x, gdf.centroid.y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_tags(df, extract_tags=None):\n",
    "\n",
    "    from sqlalchemy.dialects.postgresql import HSTORE\n",
    "\n",
    "    h = HSTORE()\n",
    "    f = h.result_processor(None, None)\n",
    "\n",
    "    # Prune the dataset to just the records that have the tags we want.\n",
    "    # before getting to the more expensive operation of extracting the tags.\n",
    "    # This should reduce the dataset from 24M rows to less than 6M.\n",
    "    t = df.dropna(subset=['other_tags'])\n",
    "   \n",
    "    if extract_tags:\n",
    "        flags = [t.other_tags.str.contains(e) for e in extract_tags]\n",
    "        comb_flags = [any(e) for e in list(zip(*flags))]\n",
    "\n",
    "        t = t[comb_flags]\n",
    "\n",
    "    rows = []\n",
    "    errors = []\n",
    "    for idx, r in t.set_index('osm_id')[['other_tags']].iterrows():\n",
    "        try:\n",
    "            d = f(r.other_tags)\n",
    "            if extract_tags:\n",
    "                rows.append([idx] + [d.get(e) for e in extract_tags])\n",
    "            else:\n",
    "                d['idx'] = idx\n",
    "                rows.append(d)\n",
    "        except TypeError as e:\n",
    "            errors.append(r, e)\n",
    "\n",
    "    return (rows, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the file and extract tags in multiprocessing\n",
    "N_task = 200\n",
    "tasks = [(e, extract_tags) for e in np.array_split(df, N_task)]\n",
    "\n",
    "results = run_mp(_extract_tags, tasks, 'Split OSM other_tags')\n",
    "tags = list(chain(*[e[0] for e in results]))\n",
    "errors = list(chain(*[e[1] for e in results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = pd.DataFrame(tags, columns=['osm_id'] + extract_tags)\n",
    "\n",
    "tags_df = gpd.GeoDataFrame(pd.merge(tags_df, df[['osm_id', 'highway', 'geometry']], on='osm_id'), \n",
    "                          geometry='geometry', crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df.to_crs(utm_crs).length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [rg.geoframe(f'censusgeo://2019/5/{st}/blockgroup') for st in stusab.values()]\n",
    "bg = pd.concat(frames)\n",
    "len(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frames = [rg.geoframe(f'censusgeo://2019/5/{st}/block') for st in tqdm(list(stusab.values()), desc='loading blocks')]\n",
    "#blk = pd.concat(frames)\n",
    "#len(blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(v):\n",
    "    return gh.encode(*list(map(float, v[7:-1].split()))[::-1])\n",
    "\n",
    "tags_df['geohash'] = tags_df.geometry.progress_apply(encode)\n",
    "\n",
    "\n",
    "tags_df['geometry'] = tags_df.geometry.progress_apply(shapely.wkt.loads)\n",
    "\n",
    "tags_df = gpd.GeoDataFrame(tags_df, geometry='geometry', crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df.head().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df['class'] = tags_df.loc[:, ('amenity', 'tourism', 'shop', 'leisure', 'natural', 'parking')].fillna(\n",
    "    method='ffill', axis=1).fillna(method='bfill', axis=1).iloc[:, 0]\n",
    "\n",
    "replace = {'parking': 'parking_space',\n",
    "           'pub': 'bar',\n",
    "           }\n",
    "cls = ['restaurant', 'bar', 'cafe', 'fast_food', 'supermarket', 'grave_yard', 'playground',\n",
    "       'bicycle_parking', 'park', 'fuel', 'bank', 'hotel', 'fitness_centre',\n",
    "       'laundry', 'clothes', 'convenience', 'parking', 'parking_space']\n",
    "\n",
    "t = tags_df[['geohash', 'class']].replace(replace)\n",
    "t = t[t['class'].isin(cls)]\n",
    "\n",
    "cls_df = t.groupby([t.geohash.str.slice(0, 8), 'class']).count().unstack().fillna(0).droplevel(0, axis=1)\n",
    "\n",
    "\n",
    "# At 8 digits, geohashes are, on average 4m by 20M over the US\n",
    "# At 6, 146m x 610m\n",
    "# At 4, 4Km x 20Km\n",
    "# Clip to 5 because it's really unlikely that there are actually more than 10\n",
    "# amenities in a cell.\n",
    "\n",
    "group_counts = tags_df.groupby(tags_df.geohash.str.slice(0, 8))\\\n",
    "    [['amenity', 'tourism', 'shop', 'leisure', 'natural', 'parking']].count().clip(0, 10)\n",
    "\n",
    "t = group_counts.join(cls_df, how='outer').fillna(0).astype(int)\n",
    "\n",
    "t['geometry'] = [Point(gh.decode(e)[::-1]) for e in t.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geohash_tags = gpd.GeoDataFrame(t, geometry='geometry', crs=4326).to_crs(utm_crs).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
